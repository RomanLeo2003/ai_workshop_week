{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pytorch_metric_learning torchmetrics torch clearml tqdm pandas numpy==1.26.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_train = pd.read_csv(\"/Users/rleontiev/Downloads/labeled_overall_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_test = train_test_split(df_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from clearml import Task, Logger\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from pytorch_metric_learning.losses import ProxyAnchorLoss\n",
    "from pytorch_metric_learning.trainers import MetricLossOnly\n",
    "from pytorch_metric_learning.utils import common_functions as c_f\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from torch.optim import AdamW\n",
    "import torchmetrics\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# === Настройки ===\n",
    "batch_size = 16\n",
    "embedding_size = 128  # Размерность эмбеддингов\n",
    "num_epochs = 200\n",
    "num_classes = 3\n",
    "\n",
    "# === Инициализация ClearML ===\n",
    "task = Task.init(project_name=\"Tabular_Metric_Learning\", task_name=\"MLP_ProxyAnchor\")\n",
    "logger = task.get_logger()\n",
    "print(\"Ссылка на задачу в ClearML:\", task.get_output_log_web_page())\n",
    "\n",
    "# === Модель MLP ===\n",
    "class TabularMLP(nn.Module):\n",
    "    \"\"\"Простая MLP для обработки табличных данных.\"\"\"\n",
    "    def __init__(self, input_dim, embedding_dim=128):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, embedding_dim)  # Выход — эмбеддинг размерности embedding_dim\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# === Тренер ===\n",
    "class TabularTrainer(MetricLossOnly):\n",
    "    def __init__(self, val_dataset, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.val_dataset = val_dataset\n",
    "\n",
    "        # Метрики\n",
    "        self.train_auc = torchmetrics.AUROC(task=\"multilabel\", num_labels=num_classes, average=\"macro\")\n",
    "        self.val_auc = torchmetrics.AUROC(task=\"multilabel\", num_labels=num_classes, average=\"macro\")\n",
    "\n",
    "        self.train_mcc = torchmetrics.MatthewsCorrCoef(task=\"multilabel\", num_labels=num_classes)\n",
    "        self.val_mcc = torchmetrics.MatthewsCorrCoef(task=\"multilabel\", num_labels=num_classes)\n",
    "\n",
    "        self.train_acc = torchmetrics.Accuracy(task=\"multilabel\", num_labels=num_classes, average=\"macro\")\n",
    "        self.val_acc = torchmetrics.Accuracy(task=\"multilabel\", num_labels=num_classes, average=\"macro\")\n",
    "\n",
    "        self.train_ap = torchmetrics.AveragePrecision(task=\"multilabel\", num_labels=num_classes, average=\"macro\")\n",
    "        self.val_ap = torchmetrics.AveragePrecision(task=\"multilabel\", num_labels=num_classes, average=\"macro\")\n",
    "\n",
    "    def initialize_val_dataloader(self):\n",
    "        self.val_dataloader = c_f.get_eval_dataloader(\n",
    "            self.val_dataset,\n",
    "            self.batch_size,\n",
    "            self.dataloader_num_workers,\n",
    "            self.collate_fn,\n",
    "        )\n",
    "\n",
    "    def train(self, start_epoch=1, num_epochs=1):\n",
    "        self.initialize_dataloader()\n",
    "        self.initialize_val_dataloader()\n",
    "        for self.epoch in range(start_epoch, num_epochs + 1):\n",
    "            self.set_to_train()\n",
    "            c_f.LOGGER.info(f\"TRAINING EPOCH {self.epoch}\")\n",
    "            pbar = tqdm(range(self.iterations_per_epoch))\n",
    "\n",
    "            self.train_auc.reset()\n",
    "            self.train_mcc.reset()\n",
    "            self.train_acc.reset()\n",
    "            self.train_ap.reset()\n",
    "\n",
    "            for self.iteration in pbar:\n",
    "                batch = self.get_batch()\n",
    "                self.forward_and_backward()\n",
    "                self.end_of_iteration_hook(self)\n",
    "\n",
    "                features, labels = batch\n",
    "                embeddings = self.models[\"trunk\"](features)\n",
    "\n",
    "                proxies = self.loss_funcs[\"metric_loss\"].proxies\n",
    "                cosine_sim = F.cosine_similarity(embeddings.unsqueeze(1), proxies.unsqueeze(0), dim=-1)\n",
    "                preds = (cosine_sim > 0.001).float()\n",
    "\n",
    "                self.train_auc.update(preds, labels)\n",
    "                self.train_mcc.update(preds, labels)\n",
    "                self.train_acc.update(preds, labels)\n",
    "                self.train_ap.update(preds, labels)\n",
    "\n",
    "                auc_value = self.train_auc.compute().item()\n",
    "                acc_value = self.train_acc.compute().item()\n",
    "                ap_value = self.train_ap.compute().item()\n",
    "                mcc_value = self.train_mcc.compute().item()\n",
    "\n",
    "                pbar.set_description(f\"AUC={auc_value:.4f}, ACC={acc_value:.4f}, MCC={mcc_value:.4f}, AP={ap_value:.4f}\")\n",
    "\n",
    "                # Логирование в ClearML\n",
    "                logger.report_scalar(\"Train_AUC\", \"epoch\", auc_value, self.epoch)\n",
    "                logger.report_scalar(\"Train_Accuracy\", \"epoch\", acc_value, self.epoch)\n",
    "                logger.report_scalar(\"Train_AP\", \"epoch\", ap_value, self.epoch)\n",
    "                logger.report_scalar(\"Train_MCC\", \"epoch\", mcc_value, self.epoch)\n",
    "\n",
    "            self.step_lr_schedulers(end_of_epoch=True)\n",
    "            self.zero_losses()\n",
    "\n",
    "            if self.end_of_epoch_hook(self) is False:\n",
    "                break\n",
    "\n",
    "            self.validate()\n",
    "\n",
    "    def validate(self):\n",
    "        self.set_to_eval()\n",
    "        val_pbar = tqdm(self.val_dataloader, desc=\"Validating\")\n",
    "\n",
    "        self.val_auc.reset()\n",
    "        self.val_mcc.reset()\n",
    "        self.val_acc.reset()\n",
    "        self.val_ap.reset()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in val_pbar:\n",
    "                input_ids, labels = batch\n",
    "                embeddings = self.models[\"trunk\"](input_ids)\n",
    "\n",
    "                proxies = self.loss_funcs[\"metric_loss\"].proxies\n",
    "                cos_sim = F.cosine_similarity(\n",
    "                    embeddings.unsqueeze(1), proxies.unsqueeze(0), dim=-1\n",
    "                )\n",
    "\n",
    "                preds = (cos_sim > 0.001).float()\n",
    "\n",
    "                self.val_auc.update(preds, labels.long())\n",
    "                self.val_mcc.update(preds, labels.long())\n",
    "                self.val_acc.update(preds, labels.long())\n",
    "                self.val_ap.update(preds, labels.long())\n",
    "\n",
    "        # Логируем валидационные метрики в ClearML\n",
    "        logger.report_scalar(\"Val_AUC\", \"epoch\", self.val_auc.compute().item(), self.epoch)\n",
    "        logger.report_scalar(\"Val_Accuracy\", \"epoch\", self.val_acc.compute().item(), self.epoch)\n",
    "        logger.report_scalar(\"Val_AP\", \"epoch\", self.val_ap.compute().item(), self.epoch)\n",
    "        logger.report_scalar(\"Val_MCC\", \"epoch\", self.val_mcc.compute().item(), self.epoch)\n",
    "\n",
    "        print(f\"Validation - AUC: {self.val_auc.compute():.4f}, MCC: {self.val_mcc.compute():.4f}, Acc: {self.val_acc.compute():.4f}, AP: {self.val_ap.compute():.4f}\")\n",
    "         \n",
    "\n",
    "\n",
    "    def calculate_loss(self, curr_batch):\n",
    "\n",
    "        input_ids, labels = curr_batch\n",
    "        # print(curr_batch)\n",
    "        embeddings = self.models[\"trunk\"](input_ids)  # Compute embeddings\n",
    "\n",
    "        # Compute Proxy Anchor Loss for each label independently\n",
    "        for i in range(labels.size(1)):  # Iterate over each of the 4 labels\n",
    "            curr_labels = labels[:, i]  # Select label column\n",
    "            indices_tuple = self.maybe_mine_embeddings(embeddings, curr_labels)\n",
    "            self.losses[\"metric_loss\"] += self.maybe_get_metric_loss(embeddings, curr_labels, indices_tuple)\n",
    "\n",
    "        self.losses[\"metric_loss\"] /= labels.size(1)  # Normalize loss across labels\n",
    "\n",
    "\n",
    "class TabularDataset(Dataset):\n",
    "    \"\"\"Датасет для работы с табличными фичами.\"\"\"\n",
    "    def __init__(self, df, feature_columns, target_columns):\n",
    "        self.features = df[feature_columns].values.astype(np.float32)\n",
    "        self.labels = df[target_columns].values.astype(np.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.features[idx]), torch.tensor(self.labels[idx])\n",
    "\n",
    "# === Функция для запуска обучения ===\n",
    "def main():\n",
    "    # === Подготовка данных ===\n",
    "    # df_train = pd.read_csv(\"train.csv\")\n",
    "    # df_val = pd.read_csv(\"val.csv\")\n",
    "\n",
    "    feature_columns = [col for col in df_train.columns if col not in [\"IL-4 release\", \"IL-10 release\", \"IFNg release\"]]\n",
    "    target_columns = [\"IL-4 release\", \"IL-10 release\", \"IFNg release\"]\n",
    "\n",
    "    train_dataset = TabularDataset(df_train, feature_columns, target_columns)\n",
    "    val_dataset = TabularDataset(df_test, feature_columns, target_columns)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, num_workers=0)\n",
    "\n",
    "    # === Модель ===\n",
    "    trunk = TabularMLP(input_dim=len(feature_columns), embedding_dim=embedding_size)\n",
    "    embedder = torch.nn.Identity()  # Заглушка для pytorch-metric-learning\n",
    "\n",
    "    # === Loss ===\n",
    "    loss_fn = ProxyAnchorLoss(num_classes=num_classes, embedding_size=embedding_size)\n",
    "\n",
    "    # === Оптимизаторы ===\n",
    "    trunk_optimizer = AdamW(trunk.parameters(), lr=1e-2, weight_decay=1e-5)\n",
    "    metric_loss_optimizer = AdamW(loss_fn.parameters(), lr=1e-2, weight_decay=1e-5)\n",
    "\n",
    "    # === Тренер ===\n",
    "    trainer = TabularTrainer(\n",
    "        label_hierarchy_level=\"all\",\n",
    "        models={\"trunk\": trunk, \"embedder\": embedder},\n",
    "        loss_funcs={\"metric_loss\": loss_fn},\n",
    "        optimizers={\"trunk_optimizer\": trunk_optimizer, \"metric_loss_optimizer\": metric_loss_optimizer},\n",
    "        batch_size=batch_size,\n",
    "        dataloader_num_workers=0,  # ВАЖНО: num_workers=0 решает проблему на Windows/macOS\n",
    "        dataset=train_dataset,\n",
    "        val_dataset=val_dataset\n",
    "    )\n",
    "\n",
    "    # === Запуск обучения ===\n",
    "    trainer.train(num_epochs=num_epochs)\n",
    "    print(\"Training complete!\")\n",
    "\n",
    "# === Запускаем обучение ===\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# === Функция загрузки обученной модели ===\n",
    "def load_model(model_path, input_dim, embedding_dim=128):\n",
    "    model = TabularMLP(input_dim, embedding_dim)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=torch.device(\"cpu\")))\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "# === Функция для выполнения инференса ===\n",
    "def inference(model, test_loader):\n",
    "    embeddings = []\n",
    "    with torch.no_grad():\n",
    "        for features in test_loader:\n",
    "            features = features.to(torch.float32)\n",
    "            emb = model(features)\n",
    "            embeddings.append(emb.cpu().numpy())\n",
    "    return np.vstack(embeddings)\n",
    "\n",
    "# === Функция подготовки данных ===\n",
    "def prepare_dataloader(csv_path, feature_columns, batch_size=16):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    features = df[feature_columns].values.astype(np.float32)\n",
    "    dataset = torch.utils.data.TensorDataset(torch.tensor(features))\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    return loader\n",
    "\n",
    "# === Основная функция ===\n",
    "def main(model_path, csv_path, feature_columns, output_csv):\n",
    "    input_dim = len(feature_columns)\n",
    "    model = load_model(model_path, input_dim)\n",
    "    test_loader = prepare_dataloader(csv_path, feature_columns)\n",
    "    embeddings = inference(model, test_loader)\n",
    "    \n",
    "    df_result = pd.DataFrame(embeddings, columns=[f\"emb_{i}\" for i in range(embeddings.shape[1])])\n",
    "    df_result.to_csv(output_csv, index=False)\n",
    "    print(f\"Инференс завершен. Результаты сохранены в {output_csv}\")\n",
    "\n",
    "# === Запуск ===\n",
    "if __name__ == \"__main__\":\n",
    "    model_path = \"model.pth\"  # Укажите путь к обученной модели\n",
    "    csv_path = \"test.csv\"  # Укажите путь к CSV с тестовыми данными\n",
    "    feature_columns = [\"feature1\", \"feature2\", \"feature3\"]  # Укажите список признаков\n",
    "    output_csv = \"embeddings.csv\"  # Файл для сохранения эмбеддингов\n",
    "    \n",
    "    main(model_path, csv_path, feature_columns, output_csv)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
